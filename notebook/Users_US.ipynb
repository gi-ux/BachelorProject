{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(3600000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 3600 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from time import strptime\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import plotly.express as px\n",
    "import matplotlib.mlab as mlab\n",
    "from statistics import mean\n",
    "import pylab\n",
    "import math\n",
    "import tweepy\n",
    "from botometer import Botometer\n",
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"gianluca.nogara@gmail.com\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import csv\n",
    "import glob\n",
    "from concurrent.futures import wait as futures_wait\n",
    "from concurrent.futures.process import ProcessPoolExecutor\n",
    "import logging\n",
    "import importlib\n",
    "import tweets_utils\n",
    "import json\n",
    "%autosave 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from platform import python_version\n",
    "# print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F:/COVID-19-Tweets\\\\2020-01\\\\users.csv',\n",
       " 'F:/COVID-19-Tweets\\\\2020-02\\\\users.csv',\n",
       " 'F:/COVID-19-Tweets\\\\2020-03\\\\users.csv',\n",
       " 'F:/COVID-19-Tweets\\\\2020-04\\\\users.csv',\n",
       " 'F:/COVID-19-Tweets\\\\2020-05\\\\users.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob(\"F:/COVID-19-Tweets/*/users.csv\")\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>protected</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>geo_enabled</th>\n",
       "      <th>verified</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>contributors_enabled</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>default_profile_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>624585646</td>\n",
       "      <td>624585646</td>\n",
       "      <td>Anissa Primafidyanti</td>\n",
       "      <td>prmfdynt</td>\n",
       "      <td>INA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>615</td>\n",
       "      <td>341</td>\n",
       "      <td>0</td>\n",
       "      <td>Mon Jul 02 11:16:32 +0000 2012</td>\n",
       "      <td>345</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>18072</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1134643848444096512</td>\n",
       "      <td>1134643848444096512</td>\n",
       "      <td>ùë®ùíçùíéùíÇ</td>\n",
       "      <td>allmitaquino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>adicta a las series y la fotograf√≠a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>39</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>Sat Jun 01 02:12:28 +0000 2019</td>\n",
       "      <td>1495</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1661</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1169267342208946183</td>\n",
       "      <td>1169267342208946183</td>\n",
       "      <td>Gregory Tribiani</td>\n",
       "      <td>GregoryTribiani</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Don‚Äôt kill our kids üò∑</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>84</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>Wed Sep 04 15:14:13 +0000 2019</td>\n",
       "      <td>4108</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4456</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>495615946</td>\n",
       "      <td>495615946</td>\n",
       "      <td>Nicole ‚ú®‚ú®</td>\n",
       "      <td>DenisseeNLB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sin limites, sin miedo, pasion y amor‚ô• Sagitar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>669</td>\n",
       "      <td>295</td>\n",
       "      <td>0</td>\n",
       "      <td>Sat Feb 18 04:31:41 +0000 2012</td>\n",
       "      <td>18868</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>79400</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>978397877939654656</td>\n",
       "      <td>978397877939654656</td>\n",
       "      <td>Alex Scott Samuel</td>\n",
       "      <td>ASAMUELFEATURE</td>\n",
       "      <td>North Carolina, USA</td>\n",
       "      <td>COMING: My Collection of 13 Southern Horror St...</td>\n",
       "      <td>https://t.co/ZeyuFWIQ5r</td>\n",
       "      <td>False</td>\n",
       "      <td>211</td>\n",
       "      <td>1294</td>\n",
       "      <td>0</td>\n",
       "      <td>Mon Mar 26 22:26:46 +0000 2018</td>\n",
       "      <td>2259</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5617</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id               id_str                  name  \\\n",
       "0            624585646            624585646  Anissa Primafidyanti   \n",
       "1  1134643848444096512  1134643848444096512                  ùë®ùíçùíéùíÇ   \n",
       "2  1169267342208946183  1169267342208946183      Gregory Tribiani   \n",
       "3            495615946            495615946             Nicole ‚ú®‚ú®   \n",
       "4   978397877939654656   978397877939654656     Alex Scott Samuel   \n",
       "\n",
       "       screen_name             location  \\\n",
       "0         prmfdynt                  INA   \n",
       "1     allmitaquino                  NaN   \n",
       "2  GregoryTribiani                  NaN   \n",
       "3      DenisseeNLB                  NaN   \n",
       "4   ASAMUELFEATURE  North Carolina, USA   \n",
       "\n",
       "                                         description                      url  \\\n",
       "0                                                NaN                      NaN   \n",
       "1                adicta a las series y la fotograf√≠a                      NaN   \n",
       "2                              Don‚Äôt kill our kids üò∑                      NaN   \n",
       "3  Sin limites, sin miedo, pasion y amor‚ô• Sagitar...                      NaN   \n",
       "4  COMING: My Collection of 13 Southern Horror St...  https://t.co/ZeyuFWIQ5r   \n",
       "\n",
       "   protected  followers_count  friends_count  listed_count  \\\n",
       "0      False              615            341             0   \n",
       "1      False               39             89             0   \n",
       "2      False               84            102             0   \n",
       "3      False              669            295             0   \n",
       "4      False              211           1294             0   \n",
       "\n",
       "                       created_at  favourites_count  geo_enabled  verified  \\\n",
       "0  Mon Jul 02 11:16:32 +0000 2012               345         True     False   \n",
       "1  Sat Jun 01 02:12:28 +0000 2019              1495         True     False   \n",
       "2  Wed Sep 04 15:14:13 +0000 2019              4108        False     False   \n",
       "3  Sat Feb 18 04:31:41 +0000 2012             18868         True     False   \n",
       "4  Mon Mar 26 22:26:46 +0000 2018              2259        False     False   \n",
       "\n",
       "   statuses_count  contributors_enabled  default_profile  \\\n",
       "0           18072                 False            False   \n",
       "1            1661                 False             True   \n",
       "2            4456                 False             True   \n",
       "3           79400                 False            False   \n",
       "4            5617                 False            False   \n",
       "\n",
       "   default_profile_image  \n",
       "0                  False  \n",
       "1                  False  \n",
       "2                  False  \n",
       "3                  False  \n",
       "4                  False  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for chunk in pd.read_csv(files[0], chunksize=10, lineterminator = '\\n'):\n",
    "    break\n",
    "chunk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = int(1e6)\n",
    "flag = False\n",
    "profile_n = 0\n",
    "i = 0\n",
    "profile_id = []\n",
    "profile_name = []\n",
    "# profile_loc = []\n",
    "# profile_verified = []\n",
    "# profile_creation = []\n",
    "# default_profile_image = []\n",
    "# statuses_count = []\n",
    "\n",
    "users = []\n",
    "\n",
    "# workers = 2\n",
    "cols = [u'id', u'screen_name', u'location', u'created_at', u'verified', u'statuses_count', u'default_profile_image'] \n",
    "cont = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: F:/COVID-19-Tweets\\2020-01\\users.csv\n",
      "Processing chunk 1\n",
      "Processing chunk 2\n",
      "Mese numero 1\n",
      "Reading file: F:/COVID-19-Tweets\\2020-02\\users.csv\n",
      "Processing chunk 1\n",
      "Processing chunk 2\n",
      "Processing chunk 3\n",
      "Processing chunk 4\n",
      "Processing chunk 5\n",
      "Mese numero 2\n",
      "Reading file: F:/COVID-19-Tweets\\2020-03\\users.csv\n",
      "Processing chunk 1\n",
      "Processing chunk 2\n",
      "Processing chunk 3\n",
      "Processing chunk 4\n",
      "Processing chunk 5\n",
      "Processing chunk 6\n",
      "Mese numero 3\n",
      "Reading file: F:/COVID-19-Tweets\\2020-04\\users.csv\n",
      "Processing chunk 1\n",
      "Processing chunk 2\n",
      "Processing chunk 3\n",
      "Processing chunk 4\n",
      "Processing chunk 5\n",
      "Processing chunk 6\n",
      "Mese numero 4\n",
      "Reading file: F:/COVID-19-Tweets\\2020-05\\users.csv\n",
      "Processing chunk 1\n",
      "Processing chunk 2\n",
      "Processing chunk 3\n",
      "Processing chunk 4\n",
      "Processing chunk 5\n",
      "Processing chunk 6\n",
      "Processing chunk 7\n",
      "Processing chunk 8\n",
      "Processing chunk 9\n",
      "Mese numero 5\n",
      "Time:  207.25741369999992\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "importlib.reload(tweets_utils)\n",
    "start_time = time.perf_counter()\n",
    "j = 0\n",
    "for filename in files:\n",
    "    print(f\"Reading file: {filename}\")\n",
    "    result.extend(tweets_utils.process_all_data(filename, cols, flag))\n",
    "    lista = result[j]\n",
    "    j = j + 1\n",
    "    print(f\"Mese numero {j}\")\n",
    "    for i in range(len(lista)):\n",
    "        profile_name.extend(lista[i][\"users\"])\n",
    "        profile_id.extend(lista[i][\"ids\"])\n",
    "stop_time = time.perf_counter()\n",
    "print(\"Time: \",stop_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del result\n",
    "del lista\n",
    "del chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CCDH Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mercola</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RobertKennedyJr</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TyCharleneB</td>\n",
       "      <td>removed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BusyDrT</td>\n",
       "      <td>suspended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IslamRizza</td>\n",
       "      <td>removed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DrButtar</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>unhealthytruth</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sayerjigmi</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KellyBroganMD</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DrChrisNorthrup</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DrBenTapper1</td>\n",
       "      <td>suspended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kevin Jenkins</td>\n",
       "      <td>???</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               user     status\n",
       "0           mercola     active\n",
       "1   RobertKennedyJr     active\n",
       "2       TyCharleneB    removed\n",
       "3           BusyDrT  suspended\n",
       "4        IslamRizza    removed\n",
       "5          DrButtar     active\n",
       "6    unhealthytruth     active\n",
       "7        sayerjigmi     active\n",
       "8     KellyBroganMD     active\n",
       "9   DrChrisNorthrup     active\n",
       "10     DrBenTapper1  suspended\n",
       "11    Kevin Jenkins        ???"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disinform = pd.read_csv(\"DisinformationUsers.csv\")\n",
    "disinform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def found(name, list_name=disinform[\"user\"]):\n",
    "    for i in list_name:\n",
    "        if(name == i):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "for i in profile_name:\n",
    "       if(found(i)):\n",
    "            names.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = set(names)\n",
    "with open(\"users_ccdh.csv\", 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"screen_name\"])\n",
    "    for i in names:\n",
    "        writer.writerow([i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_link = glob.glob(\"C:/Users/Gianluca/Desktop/Supsi/Git/TwitterFakeNewsComprehension/csv/users_ccdh.csv\")\n",
    "users_disinform = pd.read_csv(users_link[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: F:/COVID-19-Tweets\\2020-01\\tweets.csv\n",
      "Processing chunk 1\n",
      "Processing chunk 2\n",
      "Processing chunk 3\n",
      "Processing chunk 4\n",
      "Processing chunk 5\n",
      "Mese numero 1\n",
      "Reading file: F:/COVID-19-Tweets\\2020-02\\tweets.csv\n",
      "Processing chunk 1\n",
      "Processing chunk 2\n",
      "Processing chunk 3\n",
      "Processing chunk 4\n",
      "Processing chunk 5\n",
      "Processing chunk 6\n",
      "Processing chunk 7\n",
      "Processing chunk 8\n",
      "Processing chunk 9\n",
      "Processing chunk 10\n",
      "Processing chunk 11\n",
      "Processing chunk 12\n",
      "Mese numero 2\n",
      "Reading file: F:/COVID-19-Tweets\\2020-03\\tweets.csv\n",
      "Processing chunk 1\n",
      "Processing chunk 2\n",
      "Processing chunk 3\n",
      "Processing chunk 4\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-e9b561d8f75c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiles_tweets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Reading file: {filename}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweets_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_all_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols_tweets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musers_disinform\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"screen_name\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mlista\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Supsi\\Git\\TwitterFakeNewsComprehension\\notebooks\\tweets_utils.py\u001b[0m in \u001b[0;36mprocess_all_data\u001b[1;34m(filename, cols, flag, list_name, chunksize, workers)\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0mchunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[0mchunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataScience\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1032\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1034\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1035\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataScience\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mget_chunk\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m   1082\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m             \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_currow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1084\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1085\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataScience\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1055\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1057\u001b[1;33m         \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1058\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataScience\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2059\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2060\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2061\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2062\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2063\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "users = []\n",
    "content = []\n",
    "result = []\n",
    "cols_tweets = [u'user_screen_name',u'text']\n",
    "files_tweets = glob.glob(\"F:/COVID-19-Tweets/*/tweets.csv\")\n",
    "importlib.reload(tweets_utils)\n",
    "start_time = time.perf_counter()\n",
    "j = 0\n",
    "for filename in files_tweets:\n",
    "    print(f\"Reading file: {filename}\")\n",
    "    result.extend(tweets_utils.process_all_data(filename, cols_tweets, True, users_disinform[\"screen_name\"]))\n",
    "    lista = result[j]\n",
    "    j = j + 1\n",
    "    print(f\"Mese numero {j}\")\n",
    "    for i in range(len(lista)):\n",
    "        users.extend(lista[i][\"user\"])\n",
    "        content.extend(lista[i][\"content\"])\n",
    "\n",
    "stop_time = time.perf_counter()\n",
    "print(\"Time: \",stop_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unhealthytruth\n",
      "I disagree w mark. i agree with Del Bigtree where he wants his kids to get the measles or they have lifetime immunity. Then they would pass it onto their child temporarily with breast milk and they wouldn‚Äôt get it when they are old. Also CDC said MMR is dangerous. Whistleblower. https://t.co/RkEAg6gEcs\n",
      "-\n",
      "unhealthytruth\n",
      "Is there a dating app where I can meet other vaccines and see if there's any chemistry?\n",
      "#coronavirus #CoronavirusChino #CDC #excelsior\n",
      "-\n",
      "BusyDrT\n",
      "Why does the #GatesFoundation continue to get a free pass from all of us?  I understand how they control the CDC &amp; MSM  through funding ...... \n",
      "Whats it going to take for the 100th monkey scenario to materialize?  I feel like we are so close!üêµ #Momentum starts now...\n",
      "-\n",
      "unhealthytruth\n",
      "@UrbaneDoc4Kids @Dr_ScottK @living_gurl @sl0thluvchunk @chadhayesmd manufacturers are off the hook. If you would like to talk to him, we can arrange that as well. We also have other experts just on this area not to mention Dr. William Thompson at the CDC who talked about the cover-up https://t.co/eBeFNF9k6y\n",
      "-\n",
      "unhealthytruth\n",
      "how are you feeling about the coronavirus right now? How are you feeling that they‚Äôre going to rule out a vaccine faster than a new hip-hop single? PS I love hip-hop. I‚Äôm just saying. They roll them out real quick. #HealthNutNews https://t.co/pu43qocrUA\n",
      "-\n",
      "BusyDrT\n",
      "Chemical warfare trucks spotted rushing towards coronavirus-infected Wuhan   What do you think they might actually be spraying ? #chemicalwarfare #vaccines #coronavirus  #wuhan  #crimesagainsthumanity  https://t.co/Cg0gJKSZAM\n",
      "-\n",
      "RobertKennedyJr\n",
      "Former billionaire + pharma exec John Kapoor sentenced to 5+ years. His sentencing is the culmination of a months-long criminal trial that resulted in pharma execs tied to the #opioid epidemic. #OpioidCrisis\n",
      "\n",
      "https://t.co/IStojRBKoL\n",
      "-\n",
      "BusyDrT\n",
      "Even Robin Cook couldn‚Äôt have written a novel this suspenseful &amp; diabolical. #CoronaOutbreak #coronarvirus #BirdFlu #AvianFlu #vaccinepatents #CDC #WHO https://t.co/pesRYyB3Rh\n",
      "-\n",
      "BusyDrT\n",
      "Corona Virus Fakery And The Link To 5G Testing https://t.co/I9QYQwMBzC  #5G #EMF #Radiation #heavymetals #mitochondria  #NaturalSolutions #CoronaVirus #BirdFlu #FluPandemic #PanicInChina #FearFactor\n",
      "-\n",
      "mercola\n",
      "Coronavirus ‚Äî The Latest Pandemic Scare\n",
      "https://t.co/f3jjC5E5tE\n",
      "-\n",
      "BusyDrT\n",
      "The RSB Show 1/26/20 - @JonRappoport #Coronavirus update, China hoax, History matters https://t.co/M5EntutiTR @BusyDrT @ItsSuperDon @CancerTruthNews @JeffereyJaxen @sayerjigmi @GreenMedInfo @delbigtree @HighWireTalk @va_shiva\n",
      "-\n",
      "BusyDrT\n",
      "#Japan confirms patient with #coronavirus did NOT visit #China   https://t.co/A9Arrk6NdY\n",
      "-\n",
      "unhealthytruth\n",
      "@DrDanielGih So not only did he make himself and his family sick with the flu by pushing them to get a vaccine that is only 9% effective against the flu - he's ALSO ensured that they are ALL now MORE susceptible to the CORONAVIRUS!\n",
      "https://t.co/QS7TnZCZ3k\n",
      "-\n",
      "BusyDrT\n",
      "The highest bidder no doubt. Anyone honestly believe this is about safety ? #followthemoney #Coronarivus #coronavaccine https://t.co/dmSrOF6oz1\n",
      "-\n",
      "BusyDrT\n",
      "It‚Äôs not just California ... https://t.co/fCAJ2F8NhX\n",
      "-\n",
      "unhealthytruth\n",
      "I was born in the 70s and had been to over 20 countries before I was two years old. I met children from around the world and I never met one with autism and certainly never an adult with it. I never met kids with cancer. Now it‚Äôs a fucking epidemic and nobody is asking why.\n",
      "-\n",
      "unhealthytruth\n",
      "@LuckyMe54273384 @DarlaShine i‚Äôve lived abroad and been to many more country since I was two. Point being when we were kids there were a few children with autism or adults with autism let alone kids with cancer. Now it‚Äôs a fucking epidemic. The US lifespan is getting shorter and shorter according to science.\n",
      "-\n",
      "unhealthytruth\n",
      "@chancedite Great point. And not to mention when I was a kid we hardly had any obese children and now I have my own family members that are children that are unfortunately 200+ pounds and they aren‚Äôt even 10 years old. This is a real problem. It‚Äôs an epidemic. And it‚Äôs killing us. :(\n",
      "-\n",
      "unhealthytruth\n",
      "@ReadMoreScience @DarlaShine I lived in a VW bus with my parents on multiple continents growing up. i‚Äôve double that amount of countries and obviously met kids after age 2. never met anyone w autism until adulthood. Cancer was rare. Now it‚Äôs an epidemic and the science writers and experts are often paid off.\n",
      "-\n",
      "unhealthytruth\n",
      "@NPC92846601 @DarlaShine I grew up w my parents in a VW bus on multiple continents &amp; have doubled the amount of countries I‚Äôve been to since age 2. You can insult bc you don‚Äôt like the fact that autism was nearly nonexistent when I was a child and now it‚Äôs an epidemic. those responsible will pay soon.\n",
      "-\n",
      "unhealthytruth\n",
      "@Landau_18901 @Monstercoyliar @_mamadeb @mcfunny @carlsmythe @nancie_dolworth @bahrrt @michaelmina_lab @OK_AC @TioChango_ @BlueLionBlog @AutisticShill @FrankDElia7 @BeckyJohnson222 @JustWantHealth @KrochetxKorner @MacBaird13 @NelsonMKerr @PatrickEnrigh20 @ChrisJohnsonMD @med1cinewoman @MTB_CHUM @krebiozen @ianfmusgrave @doritmi @JaneEOpie @PhadingDark @TakeThatCDC @Plasticdoe @MarthaCurlee3 @Staci04907284 @PJMoore1958 @tigerquinn7 @MJonesnR @useemdumb @StewartDrea @WendyOrent @shepard_harley @DrLindaMD @MJinNJ80 @thereal_truther @vincristine @LinnyJackson @JolieAndrews16 @fiski70 @Rosewind2007 @PedsID4Life @troydee @StopVaxxedLies @TonyBaduy actually it‚Äôs not an opinion there  were nearly no children with autism 50 years ago when I was born &amp; now it‚Äôs an epidemic. It‚Äôs not an opinion that the life expectancy rate is decreasing here in the US &amp; those  responsible are going to pay dearly.. soon. it‚Äôs coming. i promise\n",
      "-\n",
      "BusyDrT\n",
      "Lijd everything else they touch!   https://t.co/aaxyHErCTd\n",
      "-\n",
      "BusyDrT\n",
      "#Coronavirus: Run, here come the experimental drugs...\n",
      "\n",
      "https://t.co/o8Xa0PjMfO\n",
      "\n",
      "(Foto: Cheng Min/Xinhua/AP) https://t.co/DlqLOJmF3F\n",
      "-\n",
      "BusyDrT\n",
      "What is in that disinfectant spray they are using in the photo?  Former FDA Commissioner: Japan on the ‚ÄòCusp‚Äô of a Large Coronavirus Outbreak https://t.co/ZTCzDDGqoc via @epochtimes #coronavirus #Japan #china #coronaoutbreak\n",
      "-\n",
      "BusyDrT\n",
      "The latest from #Infowars !  There's a lot more than just #coronavirus and #Ebola going on.  10 Plagues That Are Hitting Our Planet Simultaneously https://t.co/Ee6rcdFhoj\n",
      "-\n",
      "BusyDrT\n",
      "Why are 712 people in Washington State being ‚Äúmonitored‚Äù for coronavirus infections, but NOT TESTED? ‚Äì https://t.co/0TKHtlwxGv https://t.co/QAMyYZIi9F\n",
      "-\n",
      "BusyDrT\n",
      "Florida officials mum on coronavirus tests of state residents https://t.co/J6O5Ym7Vcl  #cornonavirus #coronaoutbreak #vaxxter #FloridaCoronaVirus\n",
      "-\n",
      "BusyDrT\n",
      "#ChinesePneumonia  (CoronaVirus) &amp; #Tamiflu?   Why?????#https://www.medicinenet.com/script/main/art.asp?articlekey=227412\n",
      "-\n",
      "BusyDrT\n",
      "‚ÄòThe results look good so far:‚Äô Thai doctors tout promising treatment for Wuhan coronavirus https://t.co/23Muwq1nVU  Components of HIV in #CoronaVirus.  Any updates on this?\n",
      "-\n",
      "BusyDrT\n",
      "What Wuhan trials were they doing at the time of the Wuhan ‚Äòoutbreak?!  Is anyone asking these questions? @LaLaRueFrench75 ?\n",
      "\n",
      "https://t.co/NeGeNGxF9k\n",
      "-\n",
      "unhealthytruth\n",
      "Breaking: FEMA camp will be used for Quarantine center for coronavirus. Local authorities  are furious and unprepared and Say it‚Äôs a really bad idea. Unfortunately it cuts the best of the video off for the congressman says don‚Äôt do it. https://t.co/KkR1dWfscu\n",
      "-\n",
      "mercola\n",
      "A protocol of intravenous vitamin C with hydrocortisone and thiamine has been shown to dramatically improve chances of survival from sepsis. Could the same treatment work for the Coronavirus?\n",
      "https://t.co/8jXNWFF232\n",
      "-\n",
      "RobertKennedyJr\n",
      "Chinese leader Xi Jinping didn‚Äôt actually admit that the #coronavirus now devastating large swaths of #China had escaped from one of the country‚Äôs bioresearch labs. But the very next day, evidence emerged suggesting that this is exactly what happened.\n",
      "\n",
      "https://t.co/0MGntyD1ZR\n",
      "-\n",
      "BusyDrT\n",
      "‚ÄúThe CDC declined to comment‚Äù\n",
      "on a study that undermines their ‚Äúvaccine science is settled‚Äù mantra. \n",
      "https://t.co/iDoGZmJDWy\n",
      "-\n",
      "BusyDrT\n",
      "They‚Äôre moving at the speed of light ..... #coronavirus #coronavaccine https://t.co/AlJWp2EEvu\n",
      "-\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-bf7b1a56334c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweets_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musers_disinform\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"screen_name\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m        \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m        \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m        \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Supsi\\Git\\TwitterFakeNewsComprehension\\notebooks\\tweets_utils.py\u001b[0m in \u001b[0;36mfound\u001b[1;34m(name, list_name)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataScience\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    811\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 813\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(len(users)):\n",
    "    if(tweets_utils.found(users[i], users_disinform[\"screen_name\"])):\n",
    "        print(users[i])\n",
    "        print(content[i])\n",
    "        print(\"-\")\n",
    "        count = count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering - few information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- no profile pic\n",
    "- numero nei tweet\n",
    "- data di creazione del profilo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del result\n",
    "# print(len(profile_creation))\n",
    "# print(len(profile_id))\n",
    "# print(len(default_profile_image))\n",
    "# print(len(profile_verified))\n",
    "# print(len(statuses_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "d = datetime(2020,1,1)\n",
    "could_be_bots = []\n",
    "coord = []\n",
    "count = 0\n",
    "for i in range(len(profile_id)):\n",
    "    if((profile_creation[i] >= d) & (profile_verified[i] == False) & \n",
    "       (statuses_count[i] >= 100) & (default_profile_image[i] == True)):  \n",
    "        could_be_bots.append((profile_id[i], profile_name[i]))\n",
    "        coord.append(profile_loc[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(could_be_bots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('users.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"id\", \"screen_name\"])\n",
    "    for i in range(len(could_be_bots)):\n",
    "        writer.writerow([could_be_bots[i][0], could_be_bots[i][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('users.csv')\n",
    "df = df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"prova.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"score_results.json\",)\n",
    "score = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in score:\n",
    "    print(score[i][\"scores\"])\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
