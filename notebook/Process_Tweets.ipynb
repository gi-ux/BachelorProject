{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(3600000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 3600 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import datetime\n",
    "import plotly.express as px\n",
    "# import matplotlib.mlab as mlab\n",
    "# from statistics import mean\n",
    "# import pylab\n",
    "import math\n",
    "# import tweepy\n",
    "# from botometer import Botometer\n",
    "# from geopy.geocoders import Nominatim\n",
    "# geolocator = Nominatim(user_agent=\"gianluca.nogara@gmail.com\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from time import perf_counter\n",
    "import glob\n",
    "import tweets_utils\n",
    "import csv\n",
    "import importlib\n",
    "%autosave 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_tweets = glob.glob(\"F:/COVID-19-Tweets/*/tweets.csv\")\n",
    "files_users = glob.glob(\"F:/COVID-19-Tweets/*/users.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F:/COVID-19-Tweets\\\\2020-01\\\\tweets.csv',\n",
       " 'F:/COVID-19-Tweets\\\\2020-02\\\\tweets.csv',\n",
       " 'F:/COVID-19-Tweets\\\\2020-03\\\\tweets.csv',\n",
       " 'F:/COVID-19-Tweets\\\\2020-04\\\\tweets.csv',\n",
       " 'F:/COVID-19-Tweets\\\\2020-05\\\\tweets.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>...</th>\n",
       "      <th>quoted_status_text</th>\n",
       "      <th>quoted_status_created_at</th>\n",
       "      <th>quoted_user_id</th>\n",
       "      <th>quoted_user_created_at</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>symbols</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>urls</th>\n",
       "      <th>polls</th>\n",
       "      <th>media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1219752899636613121</td>\n",
       "      <td>1219752899636613121</td>\n",
       "      <td>Tue Jan 21 22:45:27 +0000 2020</td>\n",
       "      <td>1110906564158869505</td>\n",
       "      <td>Huerconetzin</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Mar 27 14:08:59 +0000 2019</td>\n",
       "      <td>@CDC has activated its emergency operations ce...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'text': 'coronavirus', 'indices': [94, 106]}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'AnneKPIX', 'name': 'Anne Mak...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1219768733310291969</td>\n",
       "      <td>1219768733310291969</td>\n",
       "      <td>Tue Jan 21 23:48:22 +0000 2020</td>\n",
       "      <td>1214557289606242304</td>\n",
       "      <td>JustAnotherAme4</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Jan 07 14:40:19 +0000 2020</td>\n",
       "      <td>Soon, passengers from Wuhan to the US, on dire...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'cnni', 'name': 'CNN Internat...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1219768903116607488</td>\n",
       "      <td>1219768903116607488</td>\n",
       "      <td>Tue Jan 21 23:49:03 +0000 2020</td>\n",
       "      <td>426033838</td>\n",
       "      <td>HHSRegion8</td>\n",
       "      <td>True</td>\n",
       "      <td>Thu Dec 01 19:14:42 +0000 2011</td>\n",
       "      <td>The first human infection with new #coronaviru...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'text': 'coronavirus', 'indices': [47, 59]}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'CDCgov', 'name': 'CDC', 'id'...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1219753863940648965</td>\n",
       "      <td>1219753863940648965</td>\n",
       "      <td>Tue Jan 21 22:49:17 +0000 2020</td>\n",
       "      <td>2252416118</td>\n",
       "      <td>Paxman42</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Dec 18 19:04:31 +0000 2013</td>\n",
       "      <td>Where is our FEDERAL vaccination education cam...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'text': 'lungcancer', 'indices': [103, 114]}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'OurWarOnCancer', 'name': 'Ou...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1219755288988798981</td>\n",
       "      <td>1219755288988798981</td>\n",
       "      <td>Tue Jan 21 22:54:57 +0000 2020</td>\n",
       "      <td>738000529775697920</td>\n",
       "      <td>beerhowell</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Jun 01 13:33:32 +0000 2016</td>\n",
       "      <td>Breaking News: The first U.S. case of the Wuha...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'nytimes', 'name': 'The New Y...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id               id_str                      created_at  \\\n",
       "0  1219752899636613121  1219752899636613121  Tue Jan 21 22:45:27 +0000 2020   \n",
       "1  1219768733310291969  1219768733310291969  Tue Jan 21 23:48:22 +0000 2020   \n",
       "2  1219768903116607488  1219768903116607488  Tue Jan 21 23:49:03 +0000 2020   \n",
       "3  1219753863940648965  1219753863940648965  Tue Jan 21 22:49:17 +0000 2020   \n",
       "4  1219755288988798981  1219755288988798981  Tue Jan 21 22:54:57 +0000 2020   \n",
       "\n",
       "               user_id user_screen_name  user_verified  \\\n",
       "0  1110906564158869505     Huerconetzin          False   \n",
       "1  1214557289606242304  JustAnotherAme4          False   \n",
       "2            426033838       HHSRegion8           True   \n",
       "3           2252416118         Paxman42          False   \n",
       "4   738000529775697920       beerhowell          False   \n",
       "\n",
       "                  user_created_at  \\\n",
       "0  Wed Mar 27 14:08:59 +0000 2019   \n",
       "1  Tue Jan 07 14:40:19 +0000 2020   \n",
       "2  Thu Dec 01 19:14:42 +0000 2011   \n",
       "3  Wed Dec 18 19:04:31 +0000 2013   \n",
       "4  Wed Jun 01 13:33:32 +0000 2016   \n",
       "\n",
       "                                                text  \\\n",
       "0  @CDC has activated its emergency operations ce...   \n",
       "1  Soon, passengers from Wuhan to the US, on dire...   \n",
       "2  The first human infection with new #coronaviru...   \n",
       "3  Where is our FEDERAL vaccination education cam...   \n",
       "4  Breaking News: The first U.S. case of the Wuha...   \n",
       "\n",
       "                                              source  coordinates  ...  \\\n",
       "0  <a href=\"http://twitter.com/download/android\" ...          NaN  ...   \n",
       "1  <a href=\"http://twitter.com/download/android\" ...          NaN  ...   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...          NaN  ...   \n",
       "3  <a href=\"http://twitter.com/download/android\" ...          NaN  ...   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...          NaN  ...   \n",
       "\n",
       "   quoted_status_text  quoted_status_created_at  quoted_user_id  \\\n",
       "0                 NaN                       NaN             NaN   \n",
       "1                 NaN                       NaN             NaN   \n",
       "2                 NaN                       NaN             NaN   \n",
       "3                 NaN                       NaN             NaN   \n",
       "4                 NaN                       NaN             NaN   \n",
       "\n",
       "   quoted_user_created_at                                         hashtags  \\\n",
       "0                     NaN  [{'text': 'coronavirus', 'indices': [94, 106]}]   \n",
       "1                     NaN                                               []   \n",
       "2                     NaN   [{'text': 'coronavirus', 'indices': [47, 59]}]   \n",
       "3                     NaN  [{'text': 'lungcancer', 'indices': [103, 114]}]   \n",
       "4                     NaN                                               []   \n",
       "\n",
       "  symbols                                      user_mentions  urls  polls  \\\n",
       "0      []  [{'screen_name': 'AnneKPIX', 'name': 'Anne Mak...    []     []   \n",
       "1      []  [{'screen_name': 'cnni', 'name': 'CNN Internat...    []     []   \n",
       "2      []  [{'screen_name': 'CDCgov', 'name': 'CDC', 'id'...    []     []   \n",
       "3      []  [{'screen_name': 'OurWarOnCancer', 'name': 'Ou...    []     []   \n",
       "4      []  [{'screen_name': 'nytimes', 'name': 'The New Y...    []     []   \n",
       "\n",
       "   media  \n",
       "0     []  \n",
       "1     []  \n",
       "2     []  \n",
       "3     []  \n",
       "4     []  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunksize = 10\n",
    "for chunk in pd.read_csv(files_tweets[0], chunksize=10, lineterminator = '\\n'):\n",
    "    df = chunk\n",
    "    break\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 10\n",
    "for chunk in pd.read_csv(files_users[0], chunksize=10, lineterminator = '\\n'):\n",
    "    df = chunk\n",
    "    break\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # chunksize = int(1e6)\n",
    "# total_tweets = 0\n",
    "# original_n = 0\n",
    "# retweet_n = 0\n",
    "# reply_n = 0\n",
    "\n",
    "# users = []\n",
    "users_retweet = []\n",
    "users_retweeted = []\n",
    "users_reply = []\n",
    "users_replied = []\n",
    "users_original = []\n",
    "# users_quoted = []\n",
    "\n",
    "# ids = []\n",
    "# ids_retweet = []\n",
    "# ids_retweeted = []\n",
    "# ids_reply = []\n",
    "# ids_replied = []\n",
    "# ids_original = []\n",
    "# ids_quoted = []\n",
    "# dates = []\n",
    "\n",
    "\n",
    "cols_tweets = [u'user_id',u'user_screen_name', \n",
    "        u'rt_user_screen_name', u'rt_user_id', \n",
    "        u'in_reply_to_screen_name', u'in_reply_to_user_id',\n",
    "        u'created_at', u'text', \n",
    "        u'rt_created_at', u'in_reply_to_status_id'] \n",
    "\n",
    "cols_users = [u'id', u'screen_name', u'verified'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(filename, serie_id, serie_user):\n",
    "    filename = filename + \".csv\"\n",
    "    with open(filename, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"id\", \"screen_name\"])\n",
    "        for i in range(len(serie_id)):\n",
    "            writer.writerow([serie_id.keys()[i], serie_user.keys()[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_series(list_id, flag):\n",
    "    if(flag == True):\n",
    "        for i in range(len(list_id)):\n",
    "                list_id[i] = str(int(list_id[i]))\n",
    "    list_id = pd.Series(list_id).value_counts().sort_values(ascending=False)[:int(2e4)]\n",
    "    return list_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def id_user(user, u_id=u_id):\n",
    "#     for i in range(len(u_id)):\n",
    "#         if(user == u_id[i][1]):\n",
    "#             return u_id[i][0]\n",
    "#     return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_verified(user, u_id=u_id):\n",
    "#     for i in range(len(u_id)):\n",
    "#         if(user == u_id[i][1]):\n",
    "#             if(u_id[i][2] == True):\n",
    "#                 return True\n",
    "#     return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "importlib.reload(tweets_utils)\n",
    "start_time = time.perf_counter()\n",
    "j = 0\n",
    "for filename in files_users:\n",
    "    print(f\"Reading file: {filename}\")\n",
    "    result.extend(tweets_utils.process_all_data(filename, cols_users, False))\n",
    "    lista = result[j]\n",
    "    j = j + 1\n",
    "    print(f\"Mese numero {j}\")\n",
    "    for i in range(len(lista)):\n",
    "        users.extend(lista[i][\"users\"])\n",
    "        ids.extend(lista[i][\"ids\"])\n",
    "        verified.extend(lista[i][\"verified\"])\n",
    "\n",
    "for i in range(len(users)):\n",
    "    u_id.append((ids[i], users[i], verified[i]))\n",
    "    \n",
    "stop_time = time.perf_counter()\n",
    "print(\"Time: \",stop_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del users\n",
    "del ids\n",
    "del verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: F:/COVID-19-Tweets\\2020-01\\tweets.csv\n",
      "Processing chunk 1\n",
      "Processing chunk 2\n",
      "Processing chunk 3\n",
      "Processing chunk 4\n",
      "Processing chunk 5\n",
      "Mese numero 1\n",
      "Reading file: F:/COVID-19-Tweets\\2020-02\\tweets.csv\n",
      "Processing chunk 1\n",
      "Processing chunk 2\n",
      "Processing chunk 3\n",
      "Processing chunk 4\n",
      "Processing chunk 5\n",
      "Processing chunk 6\n",
      "Processing chunk 7\n",
      "Processing chunk 8\n",
      "Processing chunk 9\n",
      "Processing chunk 10\n",
      "Processing chunk 11\n",
      "Processing chunk 12\n",
      "Mese numero 2\n",
      "Reading file: F:/COVID-19-Tweets\\2020-03\\tweets.csv\n",
      "Processing chunk 1\n",
      "Processing chunk 2\n",
      "Processing chunk 3\n",
      "Processing chunk 4\n",
      "Processing chunk 5\n",
      "Processing chunk 6\n",
      "Processing chunk 7\n",
      "Processing chunk 8\n",
      "Processing chunk 9\n",
      "Processing chunk 10\n",
      "Processing chunk 11\n",
      "Processing chunk 12\n",
      "Processing chunk 13\n",
      "Processing chunk 14\n",
      "Processing chunk 15\n",
      "Mese numero 3\n",
      "Reading file: F:/COVID-19-Tweets\\2020-04\\tweets.csv\n",
      "Processing chunk 1\n",
      "Processing chunk 2\n",
      "Processing chunk 3\n",
      "Processing chunk 4\n",
      "Processing chunk 5\n",
      "Processing chunk 6\n",
      "Processing chunk 7\n",
      "Processing chunk 8\n",
      "Processing chunk 9\n",
      "Processing chunk 10\n",
      "Processing chunk 11\n",
      "Processing chunk 12\n",
      "Processing chunk 13\n",
      "Mese numero 4\n",
      "Reading file: F:/COVID-19-Tweets\\2020-05\\tweets.csv\n",
      "Processing chunk 1\n",
      "Processing chunk 2\n",
      "Processing chunk 3\n",
      "Processing chunk 4\n",
      "Processing chunk 5\n",
      "Processing chunk 6\n",
      "Processing chunk 7\n",
      "Processing chunk 8\n",
      "Processing chunk 9\n",
      "Processing chunk 10\n",
      "Processing chunk 11\n",
      "Processing chunk 12\n",
      "Processing chunk 13\n",
      "Processing chunk 14\n",
      "Processing chunk 15\n",
      "Processing chunk 16\n",
      "Processing chunk 17\n",
      "Processing chunk 18\n",
      "Processing chunk 19\n",
      "Processing chunk 20\n",
      "Processing chunk 21\n",
      "Processing chunk 22\n",
      "Processing chunk 23\n",
      "Processing chunk 24\n",
      "Mese numero 5\n",
      "Time:  1625.3374582\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "importlib.reload(tweets_utils)\n",
    "start_time = time.perf_counter()\n",
    "j = 0\n",
    "for filename in files_tweets:\n",
    "    print(f\"Reading file: {filename}\")\n",
    "    result.extend(tweets_utils.process_all_data(filename, cols_tweets, True))\n",
    "    lista = result[j]\n",
    "    j = j + 1\n",
    "    print(f\"Mese numero {j}\")\n",
    "    for i in range(len(lista)):\n",
    "\n",
    "        users_original.extend(lista[i][\"original_users\"])\n",
    "#         ids_original.extend(lista[i][\"original_ids\"])\n",
    "\n",
    "#         ids_reply.extend(lista[i][\"reply_ids\"])\n",
    "        users_reply.extend(lista[i][\"reply_users\"])\n",
    "\n",
    "#         ids_replied.extend(lista[i][\"replied_ids\"])\n",
    "        users_replied.extend(lista[i][\"replied_users\"])\n",
    "\n",
    "#         ids_retweet.extend(lista[i][\"retweet_ids\"])\n",
    "        users_retweet.extend(lista[i][\"retweet_users\"])\n",
    "\n",
    "#         ids_retweeted.extend(lista[i][\"retweeted_ids\"])\n",
    "        users_retweeted.extend(lista[i][\"retweeted_users\"])\n",
    "\n",
    "#         total_tweets = total_tweets + lista[i][\"total_len\"]\n",
    "#         original_n = original_n + lista[i][\"original_len\"]\n",
    "#         retweet_n = retweet_n + lista[i][\"retweet_len\"]\n",
    "#         reply_n = reply_n + lista[i][\"reply_len\"]\n",
    "\n",
    "stop_time = time.perf_counter()\n",
    "print(\"Time: \",stop_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del result\n",
    "del lista\n",
    "del chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process users_retweet\n",
      "process users_retweeted\n",
      "process users_original\n",
      "process users_reply\n",
      "process users_replied\n"
     ]
    }
   ],
   "source": [
    "print(\"process users_retweet\")\n",
    "users_retweet = pd.Series(users_retweet).value_counts().sort_values(ascending=False)[:int(2e4)]\n",
    "print(\"process users_retweeted\")\n",
    "users_retweeted = pd.Series(users_retweeted).value_counts().sort_values(ascending=False)[:int(2e4)]\n",
    "print(\"process users_original\")\n",
    "users_original = pd.Series(users_original).value_counts().sort_values(ascending=False)[:int(2e4)]\n",
    "print(\"process users_reply\")\n",
    "users_reply = pd.Series(users_reply).value_counts().sort_values(ascending=False)[:int(2e4)]\n",
    "print(\"process users_replied\")\n",
    "users_replied = pd.Series(users_replied).value_counts().sort_values(ascending=False)[:int(2e4)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = [users_retweet, users_retweeted, users_original, users_reply, users_replied]\n",
    "str_lists = [\"users_retweet\", \"users_retweeted\", \"users_original\", \"users_reply\", \"users_replied\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(lists)):\n",
    "    names = list(lists[i].keys())\n",
    "    count = list(lists[i])\n",
    "    frame = { 'Name': names, 'Count': count}\n",
    "    df = pd.DataFrame(frame)\n",
    "    path = glob.glob(\"C:/Users/Gianluca/Desktop/Supsi/Git/BachelorProject/large_files/2k_tweets _count/\")\n",
    "    df.to_csv(path[0] + str_lists[i] + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_distribution(df, string):\n",
    "    index = [10, 25, 50, 75, 90]\n",
    "    perc_numpy = [np.percentile(df[\"Count\"], i, interpolation='nearest') for i in index]\n",
    "    print(perc_numpy)\n",
    "    fig = px.histogram(df[\"Count\"], title=f\"Distribution of {string} tweets\")\n",
    "    fig.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_all_distributions():\n",
    "    df = pd.read_csv(path[0] + \"users_original.csv\")\n",
    "    visualize_distribution(df, \"original\")\n",
    "    print(\"--------------------------------------------------------------------------------------\")\n",
    "    df = pd.read_csv(path[0] + \"users_reply.csv\")\n",
    "    visualize_distribution(df, \"reply\")\n",
    "    print(\"--------------------------------------------------------------------------------------\")\n",
    "    df = pd.read_csv(path[0] + \"users_replied.csv\")\n",
    "    visualize_distribution(df, \"replied\")\n",
    "    print(\"--------------------------------------------------------------------------------------\")\n",
    "    df = pd.read_csv(path[0] + \"users_retweet.csv\")\n",
    "    visualize_distribution(df, \"retweet\")\n",
    "    print(\"--------------------------------------------------------------------------------------\")\n",
    "    df = pd.read_csv(path[0] + \"users_retweeted.csv\")\n",
    "    visualize_distribution(df, \"retweeted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_all_distributions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_retweeted = list_series(ids_retweeted, True)\n",
    "users_retweeted = list_series(users_retweeted, False)\n",
    "write_file(\"prova_retweeted\", ids_retweeted, users_retweeted)\n",
    "del ids_retweeted\n",
    "del users_retweeted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_retweet = list_series(ids_retweet, True)\n",
    "users_retweet = list_series(users_retweet, False)\n",
    "write_file(\"prova_retweet\", ids_retweet, users_retweet)\n",
    "del ids_retweet\n",
    "del users_retweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasnan = lambda array: any(filter(math.isnan, ids_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasnan4(ids_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "for i in range(len(ids_original)):\n",
    "    if(math.isnan(ids_original[i])):\n",
    "        index.append(i)\n",
    "del ids_original[index[0]:index[-1]]\n",
    "del users_original[index[0]:index[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for i in range(len(ids_original)):\n",
    "    if(math.isnan(ids_original[i])):\n",
    "        index = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ids_original[index]\n",
    "del users_original[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasnan4(ids_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ids_original = list_series(ids_original, True)\n",
    "users_original = list_series(users_original, False)\n",
    "write_file(\"prova_original\", ids_original, users_original)\n",
    "del ids_original\n",
    "del users_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_replied = list_series(ids_replied, True)\n",
    "users_replied = list_series(users_replied, False)\n",
    "write_file(\"prova_replied\", ids_replied, users_replied)\n",
    "del ids_replied\n",
    "del users_replied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_reply = list_series(ids_reply, True)\n",
    "users_reply = list_series(users_reply, False)\n",
    "write_file(\"prova_reply\", ids_reply, users_reply)\n",
    "del ids_reply\n",
    "del users_reply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of total tweets: {total_tweets}')\n",
    "print(f'Number of original tweets: {original_n}')\n",
    "print(f'Number of retweet: {retweet_n}')\n",
    "print(f'Number of reply: {reply_n}')\n",
    "\n",
    "perc_original = np.around(original_n*100/total_tweets,2)\n",
    "perc_retweet = np.around(retweet_n*100/total_tweets,2)\n",
    "perc_reply = np.around(reply_n*100/total_tweets,2)\n",
    "print(f'Number of original_tweets: {perc_original}% of total tweets')\n",
    "print(f'Number of retweets: {perc_retweet}% of total tweets')\n",
    "print(f'Number of replies: {perc_reply}% of total tweets')\n",
    "\n",
    "print('Check sum == len(tweets): ',original_n + retweet_n + reply_n == total_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.bar(np.arange(3), np.asarray([original_n, retweet_n, reply_n])*(100/total_tweets))\n",
    "ax.set_xticks(np.arange(3))\n",
    "ax.set_xticklabels(['tweets', 'retweets', 'replies'])\n",
    "ax.set_ylabel('%')\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_ylim([0,100])\n",
    "ax.set_title('Distribution of Tweets')\n",
    "#plt.savefig('files/plots/tweets_division')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = \"Original Tweets\"\n",
    "retweet = \"Retweets\"\n",
    "reply = \"Replies\"\n",
    "label = [original, retweet, reply]\n",
    "data = [original_n, retweet_n, reply_n]\n",
    "explode = (0.1, 0.1, 0.1)\n",
    "  \n",
    "# Creating color parameters\n",
    "colors = ( \"lightgreen\", \"orange\", \"cyan\")\n",
    "  \n",
    "# Wedge properties\n",
    "wp = { 'linewidth' : 1, 'edgecolor' : \"black\" }\n",
    "          \n",
    "# Creating autocpt arguments\n",
    "def func(pct, allvalues):\n",
    "    absolute = int(pct / 100.*np.sum(allvalues))\n",
    "    return \"{:.1f}%\\n({:d})\".format(pct, absolute)\n",
    "  \n",
    "# Creating plot\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "wedges, texts, autotexts = ax.pie(data, \n",
    "                                  autopct = lambda pct: func(pct, data),\n",
    "                                  explode = explode, \n",
    "                                  labels = label,\n",
    "                                  shadow = True,\n",
    "                                  colors = colors,\n",
    "                                  startangle = 90,\n",
    "                                  wedgeprops = wp)\n",
    "  \n",
    "# Adding legend\n",
    "ax.legend(wedges, label,\n",
    "          title =\"Legend\",\n",
    "          loc =\"center left\",\n",
    "          bbox_to_anchor =(1, 0, 0.5, 1))\n",
    "  \n",
    "plt.setp(autotexts, size = 8, weight =\"bold\")\n",
    "ax.set_title(\"Data pie chart\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 30 - Original tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val = pd.Series(users_original)\n",
    "val = val.value_counts().sort_values(ascending=False)\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax = val[:30].plot(kind='barh', color='lightseagreen', fig=(14,14)) #orange #lightseagreen\n",
    "ax.set_title('Number of ORIGINAL tweets per user screen name (top 30)', fontsize=15)\n",
    "ax.invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 30 - Retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val = pd.Series(users_retweet)\n",
    "val = val.value_counts().sort_values(ascending=False)\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax = val[:30].plot(kind='barh', color='steelblue', fig=(14,14))\n",
    "ax.set_title('Number of RETWEETS per user screen name (top 30)', fontsize=15)\n",
    "ax.invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 30 - Retweeted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val = pd.Series(users_retweeted)\n",
    "val = val.value_counts().sort_values(ascending=False)\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax = val[:30].plot(kind='barh', color='steelblue', fig=(14,14)) #green #steelblue\n",
    "ax.set_title('Top 30 RETWEETED USERS', fontsize=15)\n",
    "ax.invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 30 - Replied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.Series(users_replied)\n",
    "val = val.value_counts().sort_values(ascending=False)\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax = val[:30].plot(kind='barh', color='darkturquoise', fig=(14,14)) #red #darkturquoise\n",
    "ax.set_title('Top 30 USERS RECEIVING A REPLY', fontsize=15)\n",
    "ax.invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 30 - Responsive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.Series(users_reply)\n",
    "val = val.value_counts().sort_values(ascending=False)\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax = val[:30].plot(kind='barh', color='darkturquoise', fig=(14,14))  #red #darkturquoise\n",
    "ax.set_title('Number of REPLIES per user screen name (top 30)', fontsize=15)\n",
    "ax.invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Daily Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.Series(dates)\n",
    "val = val.value_counts(sort=True) \n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax = val[:25].plot(kind='bar', color='green', fig=(14,14))\n",
    "ax.set_title('Number of TWEETS per day', fontsize=15)\n",
    "# ax.invert_yaxis()\n",
    "ax.set_xticklabels(val.index.format(), rotation='vertical')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
