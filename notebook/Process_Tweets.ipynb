{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(3600000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 3600 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import datetime\n",
    "# import plotly.express as px\n",
    "# import matplotlib.mlab as mlab\n",
    "# from statistics import mean\n",
    "# import pylab\n",
    "import math\n",
    "# import tweepy\n",
    "# from botometer import Botometer\n",
    "# from geopy.geocoders import Nominatim\n",
    "# geolocator = Nominatim(user_agent=\"gianluca.nogara@gmail.com\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from time import perf_counter\n",
    "import glob\n",
    "import tweets_utils\n",
    "import csv\n",
    "import importlib\n",
    "%autosave 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_tweets = glob.glob(\"F:/COVID-19-Tweets/*/tweets.csv\")\n",
    "files_users = glob.glob(\"F:/COVID-19-Tweets/*/users.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F:/COVID-19-Tweets\\\\2020-01\\\\tweets.csv',\n",
       " 'F:/COVID-19-Tweets\\\\2020-02\\\\tweets.csv',\n",
       " 'F:/COVID-19-Tweets\\\\2020-03\\\\tweets.csv',\n",
       " 'F:/COVID-19-Tweets\\\\2020-04\\\\tweets.csv',\n",
       " 'F:/COVID-19-Tweets\\\\2020-05\\\\tweets.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "chunksize = 10\n",
    "for chunk in pd.read_csv(files_tweets[0], chunksize=10, lineterminator = '\\n'):\n",
    "    df = chunk\n",
    "    break\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 10\n",
    "for chunk in pd.read_csv(files_users[0], chunksize=10, lineterminator = '\\n'):\n",
    "    df = chunk\n",
    "    break\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunksize = int(1e6)\n",
    "total_tweets = 0\n",
    "original_n = 0\n",
    "retweet_n = 0\n",
    "reply_n = 0\n",
    "\n",
    "# users = []\n",
    "# users_retweet = []\n",
    "# users_retweeted = []\n",
    "# users_reply = []\n",
    "# users_replied = []\n",
    "users_original = []\n",
    "# users_quoted = []\n",
    "\n",
    "# ids = []\n",
    "# ids_retweet = []\n",
    "# ids_retweeted = []\n",
    "# ids_reply = []\n",
    "# ids_replied = []\n",
    "ids_original = []\n",
    "# ids_quoted = []\n",
    "# dates = []\n",
    "\n",
    "users = []\n",
    "ids = []\n",
    "verified = []\n",
    "u_id = []\n",
    "cols_tweets = [u'user_id',u'user_screen_name', \n",
    "        u'rt_user_screen_name', u'rt_user_id', \n",
    "        u'in_reply_to_screen_name', u'in_reply_to_user_id',\n",
    "        u'created_at', u'text', \n",
    "        u'rt_created_at', u'in_reply_to_status_id'] \n",
    "\n",
    "cols_users = [u'id', u'screen_name', u'verified'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(filename, serie_id, serie_user):\n",
    "    filename = filename + \".csv\"\n",
    "    with open(filename, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"id\", \"screen_name\"])\n",
    "        for i in range(len(serie_id)):\n",
    "            writer.writerow([serie_id.keys()[i], serie_user.keys()[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_series(list_id, flag):\n",
    "    if(flag == True):\n",
    "        for i in range(len(list_id)):\n",
    "                list_id[i] = str(int(list_id[i]))\n",
    "    list_id = pd.Series(list_id).value_counts().sort_values(ascending=False)[:int(2e4)]\n",
    "    return list_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def id_user(user, u_id=u_id):\n",
    "#     for i in range(len(u_id)):\n",
    "#         if(user == u_id[i][1]):\n",
    "#             return u_id[i][0]\n",
    "#     return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_verified(user, u_id=u_id):\n",
    "#     for i in range(len(u_id)):\n",
    "#         if(user == u_id[i][1]):\n",
    "#             if(u_id[i][2] == True):\n",
    "#                 return True\n",
    "#     return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "importlib.reload(tweets_utils)\n",
    "start_time = time.perf_counter()\n",
    "j = 0\n",
    "for filename in files_users:\n",
    "    print(f\"Reading file: {filename}\")\n",
    "    result.extend(tweets_utils.process_all_data(filename, cols_users, False))\n",
    "    lista = result[j]\n",
    "    j = j + 1\n",
    "    print(f\"Mese numero {j}\")\n",
    "    for i in range(len(lista)):\n",
    "        users.extend(lista[i][\"users\"])\n",
    "        ids.extend(lista[i][\"ids\"])\n",
    "        verified.extend(lista[i][\"verified\"])\n",
    "\n",
    "for i in range(len(users)):\n",
    "    u_id.append((ids[i], users[i], verified[i]))\n",
    "    \n",
    "stop_time = time.perf_counter()\n",
    "print(\"Time: \",stop_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del users\n",
    "del ids\n",
    "del verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "importlib.reload(tweets_utils)\n",
    "start_time = time.perf_counter()\n",
    "j = 0\n",
    "for filename in files_tweets:\n",
    "    print(f\"Reading file: {filename}\")\n",
    "    result.extend(tweets_utils.process_all_data(filename, cols_tweets, True))\n",
    "    lista = result[j]\n",
    "    j = j + 1\n",
    "    print(f\"Mese numero {j}\")\n",
    "    for i in range(len(lista)):\n",
    "\n",
    "        users_original.extend(lista[i][\"original_users\"])\n",
    "        ids_original.extend(lista[i][\"original_ids\"])\n",
    "\n",
    "        ids_reply.extend(lista[i][\"reply_ids\"])\n",
    "        users_reply.extend(lista[i][\"reply_users\"])\n",
    "\n",
    "        ids_replied.extend(lista[i][\"replied_ids\"])\n",
    "        users_replied.extend(lista[i][\"replied_users\"])\n",
    "\n",
    "        ids_retweet.extend(lista[i][\"retweet_ids\"])\n",
    "        users_retweet.extend(lista[i][\"retweet_users\"])\n",
    "\n",
    "        ids_retweeted.extend(lista[i][\"retweeted_ids\"])\n",
    "        users_retweeted.extend(lista[i][\"retweeted_users\"])\n",
    "\n",
    "        total_tweets = total_tweets + lista[i][\"total_len\"]\n",
    "        original_n = original_n + lista[i][\"original_len\"]\n",
    "        retweet_n = retweet_n + lista[i][\"retweet_len\"]\n",
    "        reply_n = reply_n + lista[i][\"reply_len\"]\n",
    "\n",
    "stop_time = time.perf_counter()\n",
    "print(\"Time: \",stop_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del result\n",
    "del lista\n",
    "del chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_retweeted = list_series(ids_retweeted, True)\n",
    "users_retweeted = list_series(users_retweeted, False)\n",
    "write_file(\"prova_retweeted\", ids_retweeted, users_retweeted)\n",
    "del ids_retweeted\n",
    "del users_retweeted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_retweet = list_series(ids_retweet, True)\n",
    "users_retweet = list_series(users_retweet, False)\n",
    "write_file(\"prova_retweet\", ids_retweet, users_retweet)\n",
    "del ids_retweet\n",
    "del users_retweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasnan = lambda array: any(filter(math.isnan, ids_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasnan4(ids_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "for i in range(len(ids_original)):\n",
    "    if(math.isnan(ids_original[i])):\n",
    "        index.append(i)\n",
    "del ids_original[index[0]:index[-1]]\n",
    "del users_original[index[0]:index[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for i in range(len(ids_original)):\n",
    "    if(math.isnan(ids_original[i])):\n",
    "        index = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ids_original[index]\n",
    "del users_original[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasnan4(ids_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ids_original = list_series(ids_original, True)\n",
    "users_original = list_series(users_original, False)\n",
    "write_file(\"prova_original\", ids_original, users_original)\n",
    "del ids_original\n",
    "del users_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_replied = list_series(ids_replied, True)\n",
    "users_replied = list_series(users_replied, False)\n",
    "write_file(\"prova_replied\", ids_replied, users_replied)\n",
    "del ids_replied\n",
    "del users_replied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_reply = list_series(ids_reply, True)\n",
    "users_reply = list_series(users_reply, False)\n",
    "write_file(\"prova_reply\", ids_reply, users_reply)\n",
    "del ids_reply\n",
    "del users_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova = pd.read_csv(\"prova_original.csv\")\n",
    "prova"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of total tweets: {total_tweets}')\n",
    "print(f'Number of original tweets: {original_n}')\n",
    "print(f'Number of retweet: {retweet_n}')\n",
    "print(f'Number of reply: {reply_n}')\n",
    "\n",
    "perc_original = np.around(original_n*100/total_tweets,2)\n",
    "perc_retweet = np.around(retweet_n*100/total_tweets,2)\n",
    "perc_reply = np.around(reply_n*100/total_tweets,2)\n",
    "print(f'Number of original_tweets: {perc_original}% of total tweets')\n",
    "print(f'Number of retweets: {perc_retweet}% of total tweets')\n",
    "print(f'Number of replies: {perc_reply}% of total tweets')\n",
    "\n",
    "print('Check sum == len(tweets): ',original_n + retweet_n + reply_n == total_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.bar(np.arange(3), np.asarray([original_n, retweet_n, reply_n])*(100/total_tweets))\n",
    "ax.set_xticks(np.arange(3))\n",
    "ax.set_xticklabels(['tweets', 'retweets', 'replies'])\n",
    "ax.set_ylabel('%')\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_ylim([0,100])\n",
    "ax.set_title('Distribution of Tweets')\n",
    "#plt.savefig('files/plots/tweets_division')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = \"Original Tweets\"\n",
    "retweet = \"Retweets\"\n",
    "reply = \"Replies\"\n",
    "label = [original, retweet, reply]\n",
    "data = [original_n, retweet_n, reply_n]\n",
    "explode = (0.1, 0.1, 0.1)\n",
    "  \n",
    "# Creating color parameters\n",
    "colors = ( \"lightgreen\", \"orange\", \"cyan\")\n",
    "  \n",
    "# Wedge properties\n",
    "wp = { 'linewidth' : 1, 'edgecolor' : \"black\" }\n",
    "          \n",
    "# Creating autocpt arguments\n",
    "def func(pct, allvalues):\n",
    "    absolute = int(pct / 100.*np.sum(allvalues))\n",
    "    return \"{:.1f}%\\n({:d})\".format(pct, absolute)\n",
    "  \n",
    "# Creating plot\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "wedges, texts, autotexts = ax.pie(data, \n",
    "                                  autopct = lambda pct: func(pct, data),\n",
    "                                  explode = explode, \n",
    "                                  labels = label,\n",
    "                                  shadow = True,\n",
    "                                  colors = colors,\n",
    "                                  startangle = 90,\n",
    "                                  wedgeprops = wp)\n",
    "  \n",
    "# Adding legend\n",
    "ax.legend(wedges, label,\n",
    "          title =\"Legend\",\n",
    "          loc =\"center left\",\n",
    "          bbox_to_anchor =(1, 0, 0.5, 1))\n",
    "  \n",
    "plt.setp(autotexts, size = 8, weight =\"bold\")\n",
    "ax.set_title(\"Data pie chart\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 30 - Original tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val = pd.Series(users_original)\n",
    "val = val.value_counts().sort_values(ascending=False)\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax = val[:30].plot(kind='barh', color='lightseagreen', fig=(14,14)) #orange #lightseagreen\n",
    "ax.set_title('Number of ORIGINAL tweets per user screen name (top 30)', fontsize=15)\n",
    "ax.invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 30 - Retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val = pd.Series(users_retweet)\n",
    "val = val.value_counts().sort_values(ascending=False)\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax = val[:30].plot(kind='barh', color='steelblue', fig=(14,14))\n",
    "ax.set_title('Number of RETWEETS per user screen name (top 30)', fontsize=15)\n",
    "ax.invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 30 - Retweeted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val = pd.Series(users_retweeted)\n",
    "val = val.value_counts().sort_values(ascending=False)\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax = val[:30].plot(kind='barh', color='steelblue', fig=(14,14)) #green #steelblue\n",
    "ax.set_title('Top 30 RETWEETED USERS', fontsize=15)\n",
    "ax.invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 30 - Replied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.Series(users_replied)\n",
    "val = val.value_counts().sort_values(ascending=False)\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax = val[:30].plot(kind='barh', color='darkturquoise', fig=(14,14)) #red #darkturquoise\n",
    "ax.set_title('Top 30 USERS RECEIVING A REPLY', fontsize=15)\n",
    "ax.invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 30 - Responsive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.Series(users_reply)\n",
    "val = val.value_counts().sort_values(ascending=False)\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax = val[:30].plot(kind='barh', color='darkturquoise', fig=(14,14))  #red #darkturquoise\n",
    "ax.set_title('Number of REPLIES per user screen name (top 30)', fontsize=15)\n",
    "ax.invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Daily Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.Series(dates)\n",
    "val = val.value_counts(sort=True) \n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax = val[:25].plot(kind='bar', color='green', fig=(14,14))\n",
    "ax.set_title('Number of TWEETS per day', fontsize=15)\n",
    "# ax.invert_yaxis()\n",
    "ax.set_xticklabels(val.index.format(), rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(content)):\n",
    "    if ((\"#billgateseugenicist\" in content[i]) | (\"#bigpharma\" in content[i]) | \n",
    "        (\"#rockefeller\" in content[i]) | (\"#NoMRNA\" in content[i]) | \n",
    "        (\"#vaccinesfail\" in content[i]) | (\"#Hydroxychloroquine\" in content[i])):\n",
    "        print(\"------------------------- content:\")\n",
    "        print(content[i])\n",
    "        print(\"------------------------- user:\")\n",
    "        print(users[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
